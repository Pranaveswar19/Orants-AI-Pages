<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LlamaIndex Technology - Orants AI</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <a href="index.html" class="logo">Orants <span>AI</span></a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="chatbots-rag.html">AI Solutions</a></li>
                <li><a href="quantum-ai.html">Innovation Labs</a></li>
                <li><a href="llamaindex.html">Tech Stack</a></li>
                <li><a href="ai-healthcare.html">Case Studies</a></li>
            </ul>
            <a href="#contact" class="nav-cta">Request Demo</a>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-content">
            <span class="hero-tag">‚ö° Tech Stack</span>
            <h1>LlamaIndex <span class="gradient-text">Data Framework</span></h1>
            <p>The ultimate data framework for building LLM-powered applications. Transform your unstructured data into intelligent, queryable knowledge bases that power next-generation AI applications with contextual understanding and precision.</p>
            <div class="hero-buttons">
                <a href="#capabilities" class="btn-primary">Explore Capabilities</a>
                <a href="#get-started" class="btn-secondary">Get Started</a>
            </div>
        </div>
    </section>

    <!-- Core Capabilities -->
    <section class="section" id="capabilities">
        <div class="section-header">
            <div class="section-tag">Framework Features</div>
            <h2 class="section-title">Power of LlamaIndex</h2>
            <p class="section-description">A comprehensive toolkit for ingesting, structuring, and retrieving data to augment large language models with your proprietary knowledge.</p>
        </div>
        
        <div class="features-grid">
            <div class="feature-card">
                <div class="feature-icon">üìö</div>
                <h3>Data Connectors</h3>
                <p>Seamlessly ingest data from 100+ sources including databases, APIs, file systems, and cloud storage with pre-built connectors and custom integration options.</p>
                <ul class="feature-list">
                    <li>LlamaHub connector ecosystem</li>
                    <li>Google Drive, Notion, Confluence</li>
                    <li>SQL & NoSQL databases</li>
                    <li>S3, Azure Blob, GCS storage</li>
                </ul>
            </div>

            <div class="feature-card">
                <div class="feature-icon">üîç</div>
                <h3>Advanced Indexing</h3>
                <p>Multiple indexing strategies optimized for different use cases, from simple vector stores to sophisticated knowledge graphs and hierarchical indices.</p>
                <ul class="feature-list">
                    <li>Vector store indexes</li>
                    <li>Tree-based hierarchical indices</li>
                    <li>Knowledge graph indexes</li>
                    <li>Document summary indexes</li>
                </ul>
            </div>

            <div class="feature-card">
                <div class="feature-icon">üéØ</div>
                <h3>Query Engines</h3>
                <p>Powerful query interfaces that understand natural language and retrieve the most relevant information from your knowledge base with context preservation.</p>
                <ul class="feature-list">
                    <li>Semantic search</li>
                    <li>Multi-document synthesis</li>
                    <li>Streaming responses</li>
                    <li>Conversational retrieval</li>
                </ul>
            </div>

            <div class="feature-card">
                <div class="feature-icon">üß†</div>
                <h3>Data Agents</h3>
                <p>Autonomous AI agents that can reason over your data, execute multi-step tasks, and make intelligent decisions using tool augmentation.</p>
                <ul class="feature-list">
                    <li>ReAct agent framework</li>
                    <li>OpenAI function calling</li>
                    <li>Custom tool integration</li>
                    <li>Multi-agent orchestration</li>
                </ul>
            </div>

            <div class="feature-card">
                <div class="feature-icon">‚öôÔ∏è</div>
                <h3>Customization & Fine-tuning</h3>
                <p>Complete control over every aspect of your RAG pipeline with customizable prompts, embeddings, and retrieval strategies tailored to your domain.</p>
                <ul class="feature-list">
                    <li>Custom prompt templates</li>
                    <li>Embedding model selection</li>
                    <li>Retrieval parameter tuning</li>
                    <li>Response synthesizer options</li>
                </ul>
            </div>

            <div class="feature-card">
                <div class="feature-icon">üìä</div>
                <h3>Observability & Evaluation</h3>
                <p>Built-in tools for monitoring, debugging, and evaluating your LLM applications with detailed tracing and performance metrics.</p>
                <ul class="feature-list">
                    <li>LlamaDebugger integration</li>
                    <li>Callback system for logging</li>
                    <li>RAG evaluation metrics</li>
                    <li>Performance benchmarking</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Use Cases -->
    <section class="section">
        <div class="section-header">
            <div class="section-tag">Applications</div>
            <h2 class="section-title">LlamaIndex in Action</h2>
            <p class="section-description">Real-world applications powered by LlamaIndex data framework across industries.</p>
        </div>

        <div class="features-grid">
            <div class="feature-card">
                <h3>Enterprise Knowledge Bases</h3>
                <p>Transform scattered documentation, wikis, and institutional knowledge into a unified AI-powered search and Q&A system accessible to every employee.</p>
            </div>

            <div class="feature-card">
                <h3>Customer Support Automation</h3>
                <p>Build intelligent support chatbots that accurately answer customer questions by retrieving relevant information from product docs, help articles, and past tickets.</p>
            </div>

            <div class="feature-card">
                <h3>Research & Analysis Tools</h3>
                <p>Enable researchers to query vast document collections, synthesize findings across multiple papers, and discover insights from complex datasets.</p>
            </div>

            <div class="feature-card">
                <h3>Code Documentation Assistant</h3>
                <p>Create AI assistants that understand your codebase, answer technical questions, and help developers navigate complex software architectures.</p>
            </div>

            <div class="feature-card">
                <h3>Legal Document Analysis</h3>
                <p>Process and query legal contracts, case law, and regulatory documents with precision, identifying relevant clauses and precedents instantly.</p>
            </div>

            <div class="feature-card">
                <h3>Financial Report Intelligence</h3>
                <p>Analyze earnings reports, financial statements, and market data to extract insights, trends, and actionable intelligence for investment decisions.</p>
            </div>
        </div>
    </section>

    <!-- Integration Ecosystem -->
    <section class="section">
        <div class="section-header">
            <div class="section-tag">Integrations</div>
            <h2 class="section-title">Seamless Integration Ecosystem</h2>
            <p class="section-description">LlamaIndex works with your existing tools and infrastructure.</p>
        </div>

        <div class="features-grid">
            <div class="feature-card">
                <h3>LLM Providers</h3>
                <p>Support for OpenAI GPT-4, Anthropic Claude, Google PaLM, Cohere, Hugging Face models, and local LLMs like Llama 2 and Mistral.</p>
            </div>

            <div class="feature-card">
                <h3>Vector Databases</h3>
                <p>Native integration with Pinecone, Weaviate, Qdrant, Chroma, Milvus, FAISS, and other vector stores for scalable semantic search.</p>
            </div>

            <div class="feature-card">
                <h3>Observability Platforms</h3>
                <p>Built-in support for Weights & Biases, LangSmith, Arize Phoenix, and other ML monitoring tools for production deployments.</p>
            </div>

            <div class="feature-card">
                <h3>Embedding Models</h3>
                <p>Choose from OpenAI embeddings, Cohere, Hugging Face sentence transformers, or bring your own fine-tuned embedding models.</p>
            </div>

            <div class="feature-card">
                <h3>Cloud Platforms</h3>
                <p>Deploy on AWS, Azure, GCP, or edge environments with containerized deployments and serverless options.</p>
            </div>

            <div class="feature-card">
                <h3>Development Frameworks</h3>
                <p>Integrates seamlessly with LangChain, Haystack, Streamlit, Gradio, and popular Python data science tools.</p>
            </div>
        </div>
    </section>

    <!-- Advanced Features -->
    <section class="section">
        <div class="section-header">
            <div class="section-tag">Advanced Capabilities</div>
            <h2 class="section-title">Enterprise-Grade Features</h2>
            <p class="section-description">Production-ready features for building robust, scalable LLM applications.</p>
        </div>

        <div class="features-grid">
            <div class="feature-card">
                <h3>Hybrid Search</h3>
                <p>Combine semantic vector search with traditional keyword search and metadata filtering for optimal retrieval accuracy across diverse query types.</p>
            </div>

            <div class="feature-card">
                <h3>Multi-Modal Support</h3>
                <p>Process and query not just text, but also images, tables, PDFs, and structured data with specialized parsers and models.</p>
            </div>

            <div class="feature-card">
                <h3>Streaming & Async</h3>
                <p>Built-in support for streaming responses and asynchronous processing for responsive user experiences and efficient resource utilization.</p>
            </div>

            <div class="feature-card">
                <h3>Privacy & Security</h3>
                <p>Local embeddings, on-premise deployment options, and data encryption to meet enterprise security and compliance requirements.</p>
            </div>

            <div class="feature-card">
                <h3>Cost Optimization</h3>
                <p>Smart caching, prompt compression, and retrieval optimization strategies to reduce LLM API costs by up to 80%.</p>
            </div>

            <div class="feature-card">
                <h3>Version Control</h3>
                <p>Track index versions, manage data updates, and rollback capabilities for production stability and reproducibility.</p>
            </div>
        </div>
    </section>

    <!-- Implementation Guide -->
    <section class="section" id="get-started">
        <div class="section-header">
            <div class="section-tag">Getting Started</div>
            <h2 class="section-title">Build Your First LlamaIndex App</h2>
            <p class="section-description">From simple prototypes to production-grade applications in minutes.</p>
        </div>

        <div class="features-grid">
            <div class="feature-card">
                <h3>Quick Start (5 minutes)</h3>
                <p>Install LlamaIndex, load your documents, create an index, and start querying with just a few lines of Python code.</p>
                <ul class="feature-list">
                    <li>pip install llama-index</li>
                    <li>Load documents from directory</li>
                    <li>Build vector index</li>
                    <li>Query and get responses</li>
                </ul>
            </div>

            <div class="feature-card">
                <h3>Development Environment</h3>
                <p>Set up a complete development environment with Jupyter notebooks, local vector databases, and debugging tools.</p>
                <ul class="feature-list">
                    <li>Python 3.8+ environment</li>
                    <li>OpenAI or local LLM setup</li>
                    <li>Vector database installation</li>
                    <li>Debugging and monitoring</li>
                </ul>
            </div>

            <div class="feature-card">
                <h3>Production Deployment</h3>
                <p>Scale your application with containerization, load balancing, caching layers, and monitoring for enterprise workloads.</p>
                <ul class="feature-list">
                    <li>Docker containerization</li>
                    <li>Kubernetes orchestration</li>
                    <li>Redis caching layer</li>
                    <li>Production monitoring</li>
                </ul>
            </div>

            <div class="feature-card">
                <h3>Expert Support</h3>
                <p>Our team provides architecture consulting, custom development, training workshops, and ongoing technical support.</p>
                <ul class="feature-list">
                    <li>Architecture review sessions</li>
                    <li>Custom feature development</li>
                    <li>Team training programs</li>
                    <li>24/7 technical support</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Success Metrics -->
    <section class="section">
        <div class="stats-grid">
            <div class="stat-item">
                <div class="stat-number">[Number]</div>
                <div class="stat-label">[GitHub Stars Metric]</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">[Number]</div>
                <div class="stat-label">[Data Connectors Metric]</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">[Percentage]</div>
                <div class="stat-label">[Accuracy Metric]</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">[Number]</div>
                <div class="stat-label">[Applications Metric]</div>
            </div>
        </div>
    </section>

    <!-- Why Choose Us -->
    <section class="section">
        <div class="section-header">
            <div class="section-tag">Our Expertise</div>
            <h2 class="section-title">Why Choose Orants AI for LlamaIndex</h2>
            <p class="section-description">We're official LlamaIndex partners with deep expertise in building production RAG systems.</p>
        </div>

        <div class="features-grid">
            <div class="feature-card">
                <h3>Core Contributors</h3>
                <p>Our engineers are active contributors to the LlamaIndex open-source project with commits to core features and documentation.</p>
            </div>

            <div class="feature-card">
                <h3>[Number] Implementations</h3>
                <p>We've deployed LlamaIndex solutions for enterprises across finance, healthcare, legal, and technology sectors.</p>
            </div>

            <div class="feature-card">
                <h3>Custom Extensions</h3>
                <p>We build custom connectors, retrievers, and agents tailored to your specific data sources and business logic.</p>
            </div>

            <div class="feature-card">
                <h3>Performance Optimization</h3>
                <p>Expert tuning of retrieval parameters, chunk sizes, and embedding strategies to maximize accuracy and minimize costs.</p>
            </div>
        </div>
    </section>

    <!-- CTA Section -->
    <section class="cta-section">
        <h2>Ready to Build with LlamaIndex?</h2>
        <p>Transform your data into intelligent AI applications. Consult with our LlamaIndex experts to design the perfect RAG solution for your needs.</p>
        <a href="#contact" class="btn-primary">Schedule Consultation</a>
    </section>

    <!-- Footer -->
    <footer>
        <div class="footer-content">
            <div class="footer-section">
                <h3>Orants AI</h3>
                <p>Innovating the future with intelligent solutions that empower businesses and drive progress.</p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>&copy; 2024 Orants AI. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
